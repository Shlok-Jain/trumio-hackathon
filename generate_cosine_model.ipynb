{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a8684fb-ceee-4b97-8fd4-5dbe54e9741c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.3.2-cp311-cp311-win_amd64.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\aritra\\anaconda3\\envs\\new-env-pytorch\\lib\\site-packages (from gensim) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\aritra\\anaconda3\\envs\\new-env-pytorch\\lib\\site-packages (from gensim) (1.10.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\aritra\\anaconda3\\envs\\new-env-pytorch\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Downloading gensim-4.3.2-cp311-cp311-win_amd64.whl (24.0 MB)\n",
      "   ---------------------------------------- 0.0/24.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/24.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/24.0 MB 656.4 kB/s eta 0:00:37\n",
      "   ---------------------------------------- 0.2/24.0 MB 1.3 MB/s eta 0:00:19\n",
      "    --------------------------------------- 0.4/24.0 MB 2.3 MB/s eta 0:00:11\n",
      "   - -------------------------------------- 0.8/24.0 MB 3.5 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 1.0/24.0 MB 4.1 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 1.0/24.0 MB 4.1 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 1.0/24.0 MB 4.1 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 1.3/24.0 MB 3.2 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 1.9/24.0 MB 4.1 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 2.4/24.0 MB 4.8 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 3.0/24.0 MB 5.4 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 3.3/24.0 MB 5.6 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 3.6/24.0 MB 5.6 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 4.0/24.0 MB 5.7 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 4.2/24.0 MB 5.8 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 4.5/24.0 MB 5.8 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 4.8/24.0 MB 5.8 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 5.1/24.0 MB 5.8 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 5.4/24.0 MB 5.8 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 5.7/24.0 MB 5.9 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 6.0/24.0 MB 5.9 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 6.3/24.0 MB 5.9 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 6.6/24.0 MB 6.0 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 6.9/24.0 MB 6.0 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 7.2/24.0 MB 6.0 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 7.5/24.0 MB 6.0 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 7.8/24.0 MB 6.0 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 8.1/24.0 MB 6.0 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 8.4/24.0 MB 6.0 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 8.7/24.0 MB 6.0 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 9.0/24.0 MB 6.1 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 9.3/24.0 MB 6.1 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 9.6/24.0 MB 6.1 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 9.9/24.0 MB 6.1 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 10.2/24.0 MB 6.1 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 10.5/24.0 MB 6.5 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 10.8/24.0 MB 6.5 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 11.1/24.0 MB 6.5 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 11.4/24.0 MB 7.0 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 11.7/24.0 MB 6.9 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 12.0/24.0 MB 6.7 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 12.3/24.0 MB 6.7 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 12.6/24.0 MB 6.6 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 12.9/24.0 MB 6.5 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 13.2/24.0 MB 6.4 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 13.5/24.0 MB 6.4 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 13.8/24.0 MB 6.4 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 14.1/24.0 MB 6.4 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 14.4/24.0 MB 6.4 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 14.7/24.0 MB 6.4 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 15.0/24.0 MB 6.4 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 15.2/24.0 MB 6.4 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 15.6/24.0 MB 6.4 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 15.9/24.0 MB 6.4 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 16.2/24.0 MB 6.4 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 16.5/24.0 MB 6.4 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 16.8/24.0 MB 6.4 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 17.0/24.0 MB 6.4 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 17.4/24.0 MB 6.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 17.7/24.0 MB 6.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 18.0/24.0 MB 6.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 18.2/24.0 MB 6.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 18.6/24.0 MB 6.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 18.9/24.0 MB 6.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 19.1/24.0 MB 6.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 19.5/24.0 MB 6.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 19.7/24.0 MB 6.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 20.0/24.0 MB 6.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 20.3/24.0 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 20.6/24.0 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 20.9/24.0 MB 6.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 21.2/24.0 MB 6.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 21.5/24.0 MB 6.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 21.9/24.0 MB 6.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.1/24.0 MB 6.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 22.4/24.0 MB 6.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 22.7/24.0 MB 6.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 23.1/24.0 MB 6.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 23.3/24.0 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  23.7/24.0 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.0/24.0 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.0/24.0 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.0/24.0 MB 6.2 MB/s eta 0:00:00\n",
      "Installing collected packages: gensim\n",
      "Successfully installed gensim-4.3.2\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: click in c:\\users\\aritra\\anaconda3\\envs\\new-env-pytorch\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\aritra\\anaconda3\\envs\\new-env-pytorch\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2024.5.15-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     --------- ------------------------------ 10.2/42.0 kB ? eta -:--:--\n",
      "     --------------------------- ---------- 30.7/42.0 kB 325.1 kB/s eta 0:00:01\n",
      "     -------------------------------------- 42.0/42.0 kB 406.8 kB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in c:\\users\\aritra\\anaconda3\\envs\\new-env-pytorch\\lib\\site-packages (from nltk) (4.66.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\aritra\\anaconda3\\envs\\new-env-pytorch\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.5 MB 1.3 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.1/1.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.2/1.5 MB 1.8 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.5/1.5 MB 2.8 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 0.8/1.5 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 5.1 MB/s eta 0:00:00\n",
      "Downloading regex-2024.5.15-cp311-cp311-win_amd64.whl (268 kB)\n",
      "   ---------------------------------------- 0.0/269.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 269.0/269.0 kB 8.3 MB/s eta 0:00:00\n",
      "Installing collected packages: regex, nltk\n",
      "Successfully installed nltk-3.8.1 regex-2024.5.15\n",
      "Requirement already satisfied: pandas in c:\\users\\aritra\\anaconda3\\envs\\new-env-pytorch\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\aritra\\anaconda3\\envs\\new-env-pytorch\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\aritra\\anaconda3\\envs\\new-env-pytorch\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\aritra\\anaconda3\\envs\\new-env-pytorch\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\aritra\\anaconda3\\envs\\new-env-pytorch\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\aritra\\anaconda3\\envs\\new-env-pytorch\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\aritra\\anaconda3\\envs\\new-env-pytorch\\lib\\site-packages (1.24.3)\n",
      "Requirement already satisfied: requests in c:\\users\\aritra\\anaconda3\\envs\\new-env-pytorch\\lib\\site-packages (2.32.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aritra\\anaconda3\\envs\\new-env-pytorch\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aritra\\anaconda3\\envs\\new-env-pytorch\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aritra\\anaconda3\\envs\\new-env-pytorch\\lib\\site-packages (from requests) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aritra\\anaconda3\\envs\\new-env-pytorch\\lib\\site-packages (from requests) (2024.6.2)\n",
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "   ---------------------------------------- 0.0/232.6 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/232.6 kB ? eta -:--:--\n",
      "   ----- --------------------------------- 30.7/232.6 kB 660.6 kB/s eta 0:00:01\n",
      "   --------------- ----------------------- 92.2/232.6 kB 871.5 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 225.3/232.6 kB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 232.6/232.6 kB 1.6 MB/s eta 0:00:00\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n"
     ]
    }
   ],
   "source": [
    "# Install all dependencies\n",
    "!pip install gensim\n",
    "!pip install nltk\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install requests\n",
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcab5e75-9138-4302-87da-2dc46a46538b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ARITRA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import libraries\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "from numpy.linalg import norm\n",
    "from termcolor import colored\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import PyPDF2\n",
    "import re\n",
    "import plotly.graph_objects as go\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45bf588f-a709-4780-adc5-a74e0185aed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job ID</th>\n",
       "      <th>Agency</th>\n",
       "      <th>Posting Type</th>\n",
       "      <th># Of Positions</th>\n",
       "      <th>Business Title</th>\n",
       "      <th>Civil Service Title</th>\n",
       "      <th>Title Code No</th>\n",
       "      <th>Level</th>\n",
       "      <th>Job Category</th>\n",
       "      <th>Full-Time/Part-Time indicator</th>\n",
       "      <th>...</th>\n",
       "      <th>Additional Information</th>\n",
       "      <th>To Apply</th>\n",
       "      <th>Hours/Shift</th>\n",
       "      <th>Work Location 1</th>\n",
       "      <th>Recruitment Contact</th>\n",
       "      <th>Residency Requirement</th>\n",
       "      <th>Posting Date</th>\n",
       "      <th>Post Until</th>\n",
       "      <th>Posting Updated</th>\n",
       "      <th>Process Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87990</td>\n",
       "      <td>DEPARTMENT OF BUSINESS SERV.</td>\n",
       "      <td>Internal</td>\n",
       "      <td>1</td>\n",
       "      <td>Account Manager</td>\n",
       "      <td>CONTRACT REVIEWER (OFFICE OF L</td>\n",
       "      <td>40563</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>Salary range for this position is: $42,405 - $...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York City residency is generally required ...</td>\n",
       "      <td>2011-06-24T00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-06-24T00:00:00</td>\n",
       "      <td>2018-07-17T00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>97899</td>\n",
       "      <td>DEPARTMENT OF BUSINESS SERV.</td>\n",
       "      <td>Internal</td>\n",
       "      <td>1</td>\n",
       "      <td>EXECUTIVE DIRECTOR, BUSINESS DEVELOPMENT</td>\n",
       "      <td>ADMINISTRATIVE BUSINESS PROMOT</td>\n",
       "      <td>10009</td>\n",
       "      <td>M3</td>\n",
       "      <td></td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>In addition to applying through this website, ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York City residency is generally required ...</td>\n",
       "      <td>2012-01-26T00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-01-26T00:00:00</td>\n",
       "      <td>2018-07-17T00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102221</td>\n",
       "      <td>DEPT OF ENVIRONMENT PROTECTION</td>\n",
       "      <td>External</td>\n",
       "      <td>1</td>\n",
       "      <td>Project Specialist</td>\n",
       "      <td>ENVIRONMENTAL ENGINEERING INTE</td>\n",
       "      <td>20616</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>Appointments are subject to OMB approval</td>\n",
       "      <td>click the apply now button</td>\n",
       "      <td>35 hours per week/day</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York City Residency is not required for th...</td>\n",
       "      <td>2012-06-21T00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-09-07T00:00:00</td>\n",
       "      <td>2018-07-17T00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102221</td>\n",
       "      <td>DEPT OF ENVIRONMENT PROTECTION</td>\n",
       "      <td>Internal</td>\n",
       "      <td>1</td>\n",
       "      <td>Project Specialist</td>\n",
       "      <td>ENVIRONMENTAL ENGINEERING INTE</td>\n",
       "      <td>20616</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>Appointments are subject to OMB approval</td>\n",
       "      <td>click the apply now button</td>\n",
       "      <td>35 hours per week/day</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York City Residency is not required for th...</td>\n",
       "      <td>2012-06-21T00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-09-07T00:00:00</td>\n",
       "      <td>2018-07-17T00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>114352</td>\n",
       "      <td>DEPT OF ENVIRONMENT PROTECTION</td>\n",
       "      <td>Internal</td>\n",
       "      <td>5</td>\n",
       "      <td>Deputy Plant Chief</td>\n",
       "      <td>SENIOR STATIONARY ENGINEER (EL</td>\n",
       "      <td>91639</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>Appointments are subject to OMB approval    Fo...</td>\n",
       "      <td>Click \"Apply Now\" button</td>\n",
       "      <td>40 per week / day</td>\n",
       "      <td>Various</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York City residency is generally required ...</td>\n",
       "      <td>2012-12-12T00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-12-13T00:00:00</td>\n",
       "      <td>2018-07-17T00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Job ID                          Agency Posting Type  # Of Positions  \\\n",
       "0   87990    DEPARTMENT OF BUSINESS SERV.     Internal               1   \n",
       "1   97899    DEPARTMENT OF BUSINESS SERV.     Internal               1   \n",
       "2  102221  DEPT OF ENVIRONMENT PROTECTION     External               1   \n",
       "3  102221  DEPT OF ENVIRONMENT PROTECTION     Internal               1   \n",
       "4  114352  DEPT OF ENVIRONMENT PROTECTION     Internal               5   \n",
       "\n",
       "                             Business Title             Civil Service Title  \\\n",
       "0                           Account Manager  CONTRACT REVIEWER (OFFICE OF L   \n",
       "1  EXECUTIVE DIRECTOR, BUSINESS DEVELOPMENT  ADMINISTRATIVE BUSINESS PROMOT   \n",
       "2                        Project Specialist  ENVIRONMENTAL ENGINEERING INTE   \n",
       "3                        Project Specialist  ENVIRONMENTAL ENGINEERING INTE   \n",
       "4                        Deputy Plant Chief  SENIOR STATIONARY ENGINEER (EL   \n",
       "\n",
       "  Title Code No Level Job Category Full-Time/Part-Time indicator  ...  \\\n",
       "0         40563     1                                             ...   \n",
       "1         10009    M3                                          F  ...   \n",
       "2         20616     0                                          F  ...   \n",
       "3         20616     0                                          F  ...   \n",
       "4         91639     0                                          F  ...   \n",
       "\n",
       "                              Additional Information  \\\n",
       "0  Salary range for this position is: $42,405 - $...   \n",
       "1                                                      \n",
       "2           Appointments are subject to OMB approval   \n",
       "3           Appointments are subject to OMB approval   \n",
       "4  Appointments are subject to OMB approval    Fo...   \n",
       "\n",
       "                                            To Apply            Hours/Shift  \\\n",
       "0                                                                             \n",
       "1  In addition to applying through this website, ...                          \n",
       "2                         click the apply now button  35 hours per week/day   \n",
       "3                         click the apply now button  35 hours per week/day   \n",
       "4                           Click \"Apply Now\" button      40 per week / day   \n",
       "\n",
       "  Work Location 1 Recruitment Contact  \\\n",
       "0                                 NaN   \n",
       "1                                 NaN   \n",
       "2                                 NaN   \n",
       "3                                 NaN   \n",
       "4         Various                 NaN   \n",
       "\n",
       "                               Residency Requirement         Posting Date  \\\n",
       "0  New York City residency is generally required ...  2011-06-24T00:00:00   \n",
       "1  New York City residency is generally required ...  2012-01-26T00:00:00   \n",
       "2  New York City Residency is not required for th...  2012-06-21T00:00:00   \n",
       "3  New York City Residency is not required for th...  2012-06-21T00:00:00   \n",
       "4  New York City residency is generally required ...  2012-12-12T00:00:00   \n",
       "\n",
       "  Post Until      Posting Updated         Process Date  \n",
       "0        NaN  2011-06-24T00:00:00  2018-07-17T00:00:00  \n",
       "1        NaN  2012-01-26T00:00:00  2018-07-17T00:00:00  \n",
       "2        NaN  2012-09-07T00:00:00  2018-07-17T00:00:00  \n",
       "3        NaN  2012-09-07T00:00:00  2018-07-17T00:00:00  \n",
       "4        NaN  2012-12-13T00:00:00  2018-07-17T00:00:00  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('nyc-jobs-1.csv')\n",
    "# Check data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e38e0556-3b9e-47c7-b1d9-69ddd03bd4e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Job ID', 'Agency', 'Posting Type', '# Of Positions', 'Business Title',\n",
       "       'Civil Service Title', 'Title Code No', 'Level', 'Job Category',\n",
       "       'Full-Time/Part-Time indicator', 'Salary Range From', 'Salary Range To',\n",
       "       'Salary Frequency', 'Work Location', 'Division/Work Unit',\n",
       "       'Job Description', 'Minimum Qual Requirements', 'Preferred Skills',\n",
       "       'Additional Information', 'To Apply', 'Hours/Shift', 'Work Location 1',\n",
       "       'Recruitment Contact', 'Residency Requirement', 'Posting Date',\n",
       "       'Post Until', 'Posting Updated', 'Process Date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show column name\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b77d8d8b-ab95-407d-a54b-b760300ea3d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Business Title</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Minimum Qual Requirements</th>\n",
       "      <th>Preferred Skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Account Manager</td>\n",
       "      <td>Division of Economic &amp; Financial Opportunity (...</td>\n",
       "      <td>1.\\tA baccalaureate degree from an accredited ...</td>\n",
       "      <td>â€¢\\tExcellent interpersonal and organizationa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EXECUTIVE DIRECTOR, BUSINESS DEVELOPMENT</td>\n",
       "      <td>The New York City Department of Small Business...</td>\n",
       "      <td>1. A baccalaureate degree from an accredited c...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Project Specialist</td>\n",
       "      <td>Under direct supervision, perform elementary e...</td>\n",
       "      <td>A Baccalaureate degree from an accredited coll...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Project Specialist</td>\n",
       "      <td>Under direct supervision, perform elementary e...</td>\n",
       "      <td>A Baccalaureate degree from an accredited coll...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deputy Plant Chief</td>\n",
       "      <td>Under general direction, is in responsible cha...</td>\n",
       "      <td>1. Six years of full-time satisfactory experie...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Business Title  \\\n",
       "0                           Account Manager   \n",
       "1  EXECUTIVE DIRECTOR, BUSINESS DEVELOPMENT   \n",
       "2                        Project Specialist   \n",
       "3                        Project Specialist   \n",
       "4                        Deputy Plant Chief   \n",
       "\n",
       "                                     Job Description  \\\n",
       "0  Division of Economic & Financial Opportunity (...   \n",
       "1  The New York City Department of Small Business...   \n",
       "2  Under direct supervision, perform elementary e...   \n",
       "3  Under direct supervision, perform elementary e...   \n",
       "4  Under general direction, is in responsible cha...   \n",
       "\n",
       "                           Minimum Qual Requirements  \\\n",
       "0  1.\\tA baccalaureate degree from an accredited ...   \n",
       "1  1. A baccalaureate degree from an accredited c...   \n",
       "2  A Baccalaureate degree from an accredited coll...   \n",
       "3  A Baccalaureate degree from an accredited coll...   \n",
       "4  1. Six years of full-time satisfactory experie...   \n",
       "\n",
       "                                    Preferred Skills  \n",
       "0  â€¢\\tExcellent interpersonal and organizationa...  \n",
       "1                                                     \n",
       "2                                                     \n",
       "3                                                     \n",
       "4                                                     "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =df[['Business Title', 'Job Description', 'Minimum Qual Requirements', 'Preferred Skills']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93cc23ae-8af3-4c4c-beb3-cce5d2296a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                data\n",
      "0  Account Manager Division of Economic & Financi...\n",
      "1  EXECUTIVE DIRECTOR, BUSINESS DEVELOPMENT The N...\n",
      "2  Project Specialist Under direct supervision, p...\n",
      "3  Project Specialist Under direct supervision, p...\n",
      "4  Deputy Plant Chief Under general direction, is...\n"
     ]
    }
   ],
   "source": [
    "# Create a new column called 'data' and merge the values of the other columns into it\n",
    "df['data'] = df[['Business Title', 'Job Description', 'Minimum Qual Requirements', 'Preferred Skills']].apply(lambda x: ' '.join(x.dropna().astype(str)), axis=1)\n",
    "# Drop the individual columns if you no longer need them\n",
    "df.drop(['Business Title', 'Job Description', 'Minimum Qual Requirements', 'Preferred Skills'], axis=1, inplace=True)\n",
    "# Preview the updated dataframe\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9943ca3-1e36-41e2-8f24-8e1197b3bbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tag data\n",
    "data = list(df['data'])\n",
    "tagged_data = [TaggedDocument(words = word_tokenize(_d.lower()), tags = [str(i)]) for i, _d in enumerate(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d64d655-73fe-4bfe-a215-f875230c3a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34788140-6087-4a3f-9bbd-7d66b4d96f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "addf7683-cc36-4fc2-84ad-9adb8130365c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model initialization\n",
    "import multiprocessing\n",
    "model = Doc2Vec(vector_size = 50,\n",
    "                min_count = 5,\n",
    "                epochs = 100,\n",
    "                alpha = 0.001,\n",
    "                workers=multiprocessing.cpu_count()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8afc0e4-77f8-42ed-8c5f-a20af6f42e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8599\n"
     ]
    }
   ],
   "source": [
    "# Vocabulary building\n",
    "model.build_vocab(tagged_data)\n",
    "# Get the vocabulary keys\n",
    "keys = model.wv.key_to_index.keys()\n",
    "# Print the length of the vocabulary keys\n",
    "print(len(keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e9fc88d-78ac-4444-9997-4dfd8da6fa7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 1/100\n",
      "Training epoch 2/100\n",
      "Training epoch 3/100\n",
      "Training epoch 4/100\n",
      "Training epoch 5/100\n",
      "Training epoch 6/100\n",
      "Training epoch 7/100\n",
      "Training epoch 8/100\n",
      "Training epoch 9/100\n",
      "Training epoch 10/100\n",
      "Training epoch 11/100\n",
      "Training epoch 12/100\n",
      "Training epoch 13/100\n",
      "Training epoch 14/100\n",
      "Training epoch 15/100\n",
      "Training epoch 16/100\n",
      "Training epoch 17/100\n",
      "Training epoch 18/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(model\u001b[38;5;241m.\u001b[39mepochs):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain(tagged_data, \n\u001b[0;32m      5\u001b[0m                 total_examples\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mcorpus_count,\n\u001b[0;32m      6\u001b[0m                 epochs\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mepochs)\n\u001b[0;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcv_job_maching.model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel saved\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\new-env-pytorch\\Lib\\site-packages\\gensim\\models\\doc2vec.py:516\u001b[0m, in \u001b[0;36mDoc2Vec.train\u001b[1;34m(self, corpus_iterable, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    513\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moffsets\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m offsets\n\u001b[0;32m    514\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_doctags\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m start_doctags\n\u001b[1;32m--> 516\u001b[0m \u001b[38;5;28msuper\u001b[39m(Doc2Vec, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mtrain(\n\u001b[0;32m    517\u001b[0m     corpus_iterable\u001b[38;5;241m=\u001b[39mcorpus_iterable, corpus_file\u001b[38;5;241m=\u001b[39mcorpus_file,\n\u001b[0;32m    518\u001b[0m     total_examples\u001b[38;5;241m=\u001b[39mtotal_examples, total_words\u001b[38;5;241m=\u001b[39mtotal_words,\n\u001b[0;32m    519\u001b[0m     epochs\u001b[38;5;241m=\u001b[39mepochs, start_alpha\u001b[38;5;241m=\u001b[39mstart_alpha, end_alpha\u001b[38;5;241m=\u001b[39mend_alpha, word_count\u001b[38;5;241m=\u001b[39mword_count,\n\u001b[0;32m    520\u001b[0m     queue_factor\u001b[38;5;241m=\u001b[39mqueue_factor, report_delay\u001b[38;5;241m=\u001b[39mreport_delay, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\new-env-pytorch\\Lib\\site-packages\\gensim\\models\\word2vec.py:1073\u001b[0m, in \u001b[0;36mWord2Vec.train\u001b[1;34m(self, corpus_iterable, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m   1070\u001b[0m     callback\u001b[38;5;241m.\u001b[39mon_epoch_begin(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1072\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m corpus_iterable \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1073\u001b[0m     trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_epoch(\n\u001b[0;32m   1074\u001b[0m         corpus_iterable, cur_epoch\u001b[38;5;241m=\u001b[39mcur_epoch, total_examples\u001b[38;5;241m=\u001b[39mtotal_examples,\n\u001b[0;32m   1075\u001b[0m         total_words\u001b[38;5;241m=\u001b[39mtotal_words, queue_factor\u001b[38;5;241m=\u001b[39mqueue_factor, report_delay\u001b[38;5;241m=\u001b[39mreport_delay,\n\u001b[0;32m   1076\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1077\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1078\u001b[0m     trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_epoch_corpusfile(\n\u001b[0;32m   1079\u001b[0m         corpus_file, cur_epoch\u001b[38;5;241m=\u001b[39mcur_epoch, total_examples\u001b[38;5;241m=\u001b[39mtotal_examples, total_words\u001b[38;5;241m=\u001b[39mtotal_words,\n\u001b[0;32m   1080\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\new-env-pytorch\\Lib\\site-packages\\gensim\\models\\word2vec.py:1434\u001b[0m, in \u001b[0;36mWord2Vec._train_epoch\u001b[1;34m(self, data_iterable, cur_epoch, total_examples, total_words, queue_factor, report_delay, callbacks)\u001b[0m\n\u001b[0;32m   1431\u001b[0m     thread\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# make interrupting the process with ctrl+c easier\u001b[39;00m\n\u001b[0;32m   1432\u001b[0m     thread\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m-> 1434\u001b[0m trained_word_count, raw_word_count, job_tally \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_epoch_progress(\n\u001b[0;32m   1435\u001b[0m     progress_queue, job_queue, cur_epoch\u001b[38;5;241m=\u001b[39mcur_epoch, total_examples\u001b[38;5;241m=\u001b[39mtotal_examples,\n\u001b[0;32m   1436\u001b[0m     total_words\u001b[38;5;241m=\u001b[39mtotal_words, report_delay\u001b[38;5;241m=\u001b[39mreport_delay, is_corpus_file_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1437\u001b[0m )\n\u001b[0;32m   1439\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trained_word_count, raw_word_count, job_tally\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\new-env-pytorch\\Lib\\site-packages\\gensim\\models\\word2vec.py:1289\u001b[0m, in \u001b[0;36mWord2Vec._log_epoch_progress\u001b[1;34m(self, progress_queue, job_queue, cur_epoch, total_examples, total_words, report_delay, is_corpus_file_mode)\u001b[0m\n\u001b[0;32m   1286\u001b[0m unfinished_worker_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkers\n\u001b[0;32m   1288\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m unfinished_worker_count \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1289\u001b[0m     report \u001b[38;5;241m=\u001b[39m progress_queue\u001b[38;5;241m.\u001b[39mget()  \u001b[38;5;66;03m# blocks if workers too slow\u001b[39;00m\n\u001b[0;32m   1290\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m report \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# a thread reporting that it finished\u001b[39;00m\n\u001b[0;32m   1291\u001b[0m         unfinished_worker_count \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\new-env-pytorch\\Lib\\queue.py:171\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qsize():\n\u001b[1;32m--> 171\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_empty\u001b[38;5;241m.\u001b[39mwait()\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be a non-negative number\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\new-env-pytorch\\Lib\\threading.py:327\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 327\u001b[0m         waiter\u001b[38;5;241m.\u001b[39macquire()\n\u001b[0;32m    328\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "for epoch in range(model.epochs):\n",
    "    print(f\"Training epoch {epoch+1}/{model.epochs}\")\n",
    "    model.train(tagged_data, \n",
    "                total_examples=model.corpus_count,\n",
    "                epochs=model.epochs)\n",
    "\n",
    "model.save('cv_job_maching.model')\n",
    "print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6fef5b1f-4ef0-4c9c-85a2-771e9f9a37b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abhishek Kumar Tiwari.pdf',\n",
       " 'Aditya Chandrikapure.pdf',\n",
       " 'Aditya Jha.pdf',\n",
       " 'Aditya Krishna Das.pdf',\n",
       " 'Akshat Vijay.pdf',\n",
       " 'Aman Mishra.pdf',\n",
       " 'Amisha Sinha.pdf',\n",
       " 'Amit Kumar.pdf',\n",
       " 'Amruit Sahoo.pdf',\n",
       " 'Anirudh Kohli.pdf',\n",
       " 'Anirudh Sharma.pdf',\n",
       " 'Anjali Raj.pdf',\n",
       " 'Ankesh Kumar.pdf',\n",
       " 'Anurag Anand.pdf',\n",
       " 'Apoorva Tejaswi.pdf',\n",
       " 'Arihant Shukla.pdf',\n",
       " 'Aryan Kumar.pdf',\n",
       " 'Aryan Tayal.pdf',\n",
       " 'Atul Ranjan.pdf',\n",
       " 'Bharat Kabra.pdf',\n",
       " 'Bhaskar Sugana.pdf',\n",
       " 'Chirag Agarwal.pdf',\n",
       " 'Dibyendu Biswas.pdf',\n",
       " 'Dnyandeep Chavan.pdf',\n",
       " 'Dokala Avinash.pdf',\n",
       " 'Doraswamy Vamsi.pdf']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import OS module\n",
    "import os\n",
    "# Get the list of all files and directories\n",
    "path = r\"C:\\Users\\ARITRA\\Documents\\Notebooks\\Project Recommender Hackathon Trumio\\Resumes\"\n",
    "dir_list = os.listdir(path)\n",
    "dir_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6f2b310e-7832-4593-ad69-0580c275d642",
   "metadata": {},
   "outputs": [],
   "source": [
    "resumes = []\n",
    "for name in dir_list:\n",
    "    file_path = f\"Resumes\\{name}\"\n",
    "    pdf = PyPDF2.PdfReader(file_path)\n",
    "    resume = \"\"\n",
    "    for i in range(len(pdf.pages)):\n",
    "        pageObj = pdf.pages[i]\n",
    "        resume += pageObj.extract_text()\n",
    "    resumes.append(resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "88a91c0f-749a-449a-b6dd-c3dec26db4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "jd1 = \"\"\"\n",
    "Hiring - Chatbot\n",
    "You are designing a chatbot that returns the best engineers for a given set of instructions\n",
    "provided to the chatbot. The chatbot should interface with the user and return results\n",
    "dynamically based on the information provided.\n",
    "Information you should support for the search:\n",
    "● Whether the worker is full-time or part-time\n",
    "● Whether the worker fits the user’s budget\n",
    "● Whether the worker has the skills that the user wants (i.e. Python, React, AWS)\n",
    "● Other queries in natural language (i.e. “worked at a big tech company”)\n",
    "Example queries:\n",
    "● “I want to hire someone with experience in Python and Node. My budget is $10000 a\n",
    "month.”\n",
    "○ The chatbot follows up asking whether the user wants a full-time or part-time\n",
    "worker after showing some results\n",
    "● “I want to hire someone who worked at a big tech company. I have an unlimited budget.\n",
    "They should be proficient in Python.”\n",
    "○ The chatbot follows up asking whether the user wants a full-time or part-time\n",
    "worker after showing some results\n",
    "● “I want to hire a developer”\n",
    "○ The chatbot follows up asking for the skills, budget, and whether the worker is\n",
    "part-time or full-time. The chatbot shows results after skills are provided\n",
    "This search has two components: a scalar part (part-time / full-time, budget, and skills, which\n",
    "are all stored in the database) and a semantic part (supporting all other queries in natural\n",
    "language, which will require embeddings and a vector database).\n",
    "Your search should be as low latency as possible. You will likely need to utilise various DB tricks\n",
    "to make this happen.\n",
    "You should also build out a front-end to make testing this chatbot easier.\n",
    "Additionally, your search should still work properly if users from the database are deleted or if\n",
    "their resume information is mutated (which requires giving some thought to the connection\n",
    "between Pinecone and the SQL database).\n",
    "Lastly, you should design a ranking algorithm to prioritize how the candidates are returned in the\n",
    "search. This should take into account the following:\n",
    "● Their background (work experience, education, etc.)\n",
    "● Github data (pre-processed and scored from their Github username). Note: these are not\n",
    "the actual Github usernames of the individuals, they are randomly selected public Github\n",
    "usernames.\n",
    "It is entirely up to you how you implement this ranking and how granular you want to be with\n",
    "scoring each component of a candidate’s background. It is also up to you how you want to\n",
    "prioritize each score when returning candidates.\n",
    "Tips and Recommendations\n",
    "Tools I’d recommend using for various components of the problem statement:\n",
    "● Visualizing data in the DB: https://www.mysql.com/products/workbench/\n",
    "● Stateless, lightweight tasks: https://cloud.google.com/functions?hl=en\n",
    "● Stateful, heavyweight tasks: https://cloud.google.com/run?hl=en or your own Google VM\n",
    "● Vector database for the semantic component of the search: https://www.pinecone.io/ or\n",
    "https://www.weaviate.io or something similar\n",
    "● Embeddings model and reranker for the semantic search:\n",
    "https://huggingface.co/BAAI/bge-large-en-v1.5#using-sentence-transformers (you could\n",
    "also use OpenAI’s text embeddings)\n",
    "You will likely need to use embeddings and a vector database for the semantic component of\n",
    "the search. Embeddings are numerical representations of text — for the purposes of this trial,\n",
    "you should embed the text that should be searchable via natural language (work experience,\n",
    "education, etc.). Then, you can take the semantic component of the search query, embed it, and\n",
    "do a cosine similarity to return the most relevant items. You will need to build out a way to\n",
    "present the data between the scalar elements of the search and the semantic elements.\n",
    "Tutorial for vector databases: https://www.pinecone.io/learn/vector-database/\n",
    "If you have any questions, feel free to reach out!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f7e37231-07e8-4c10-a485-ef580a33731c",
   "metadata": {},
   "outputs": [],
   "source": [
    "jd2 = \"\"\"\n",
    "Show Me The Money\n",
    "The goal of the project is to build a simple one page application to display the Balance\n",
    "Sheet Report from Xero.\n",
    "Please read through the API documentation at\n",
    "https://developer.xero.com/documentation/api/accounting/reports#balance-sheet.\n",
    "Use mock Xero Balance Sheet API docker image available at\n",
    "https://hub.docker.com/r/jaypeng2015/show-me-the-money.\n",
    "The Server runs on http with port 3000, and the api path is /api.xro/2.0/Reports/BalanceSheet\n",
    "once you have it running.\n",
    "The system should consist of the following:\n",
    "● Backend - Any typed Language (except Java)\n",
    "○ Assume that the authentication with Xero is already done.\n",
    "○ Provide API endpoint to get data from Xero API for the frontend to use.\n",
    "○ Consider error handling.\n",
    "○ Consider unit tests.\n",
    "● Frontend - Typescript + React\n",
    "○ Display the results in a table based on the data structure return from Xero.\n",
    "○ Consider unit tests.\n",
    "Consider containerise your solution.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5307ebb9-5845-4166-b8b0-322685861a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "jd3 = \"\"\"\n",
    "Hiring - Chatbot\n",
    "You are designing a chatbot that returns the best engineers for a given set of instructions\n",
    "provided to the chatbot. The chatbot should interface with the user and return results\n",
    "dynamically based on the information provided.\n",
    "Information you should support for the search:\n",
    "● Whether the worker is full-time or part-time\n",
    "● Whether the worker fits the user’s budget\n",
    "● Whether the worker has the skills that the user wants (i.e. Python, React, AWS)\n",
    "● Other queries in natural language (i.e. “worked at a big tech company”)\n",
    "Example queries:\n",
    "● “I want to hire someone with experience in Python and Node. My budget is $10000 a\n",
    "month.”\n",
    "○ The chatbot follows up asking whether the user wants a full-time or part-time\n",
    "worker after showing some results\n",
    "● “I want to hire someone who worked at a big tech company. I have an unlimited budget.\n",
    "They should be proficient in Python.”\n",
    "○ The chatbot follows up asking whether the user wants a full-time or part-time\n",
    "worker after showing some results\n",
    "● “I want to hire a developer”\n",
    "○ The chatbot follows up asking for the skills, budget, and whether the worker is\n",
    "part-time or full-time. The chatbot shows results after skills are provided\n",
    "This search has two components: a scalar part (part-time / full-time, budget, and skills, which\n",
    "are all stored in the database) and a semantic part (supporting all other queries in natural\n",
    "language, which will require embeddings and a vector database).\n",
    "Your search should be as low latency as possible. You will likely need to utilise various DB tricks\n",
    "to make this happen.\n",
    "You should also build out a front-end to make testing this chatbot easier.\n",
    "Additionally, your search should still work properly if users from the database are deleted or if\n",
    "their resume information is mutated (which requires giving some thought to the connection\n",
    "between Pinecone and the SQL database).\n",
    "Lastly, you should design a ranking algorithm to prioritize how the candidates are returned in the\n",
    "search. This should take into account the following:\n",
    "● Their background (work experience, education, etc.)\n",
    "● Github data (pre-processed and scored from their Github username). Note: these are not\n",
    "the actual Github usernames of the individuals, they are randomly selected public Github\n",
    "usernames.\n",
    "It is entirely up to you how you implement this ranking and how granular you want to be with\n",
    "scoring each component of a candidate’s background. It is also up to you how you want to\n",
    "prioritize each score when returning candidates.\n",
    "Tips and Recommendations\n",
    "Tools I’d recommend using for various components of the problem statement:\n",
    "● Visualizing data in the DB: https://www.mysql.com/products/workbench/\n",
    "● Stateless, lightweight tasks: https://cloud.google.com/functions?hl=en\n",
    "● Stateful, heavyweight tasks: https://cloud.google.com/run?hl=en or your own Google VM\n",
    "● Vector database for the semantic component of the search: https://www.pinecone.io/ or\n",
    "https://www.weaviate.io or something similar\n",
    "● Embeddings model and reranker for the semantic search:\n",
    "https://huggingface.co/BAAI/bge-large-en-v1.5#using-sentence-transformers (you could\n",
    "also use OpenAI’s text embeddings)\n",
    "You will likely need to use embeddings and a vector database for the semantic component of\n",
    "the search. Embeddings are numerical representations of text — for the purposes of this trial,\n",
    "you should embed the text that should be searchable via natural language (work experience,\n",
    "education, etc.). Then, you can take the semantic component of the search query, embed it, and\n",
    "do a cosine similarity to return the most relevant items. You will need to build out a way to\n",
    "present the data between the scalar elements of the search and the semantic elements.\n",
    "Tutorial for vector databases: https://www.pinecone.io/learn/vector-database/\n",
    "If you have any questions, feel free to reach out!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5c7f1619-a10a-47e9-a623-4013735ad75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "jd4 = \"\"\"\n",
    "Web Scraper\n",
    "Objective: Given that summer holidays have already started, hotels and resorts in the\n",
    "top tourist destinations of India are already facing high demand. However, properties\n",
    "have different ways of managing inventories at different platforms. When I as a traveller\n",
    "go to platform1, a hotel/resort may show as Out of Stock there but another platform still\n",
    "shows inventory left. For non tech savvy travelers, it might be very hectic and\n",
    "cumbersome to look for availability on different platforms.\n",
    "Create a web scraping tool where if given a property, checkin/checkout dates and\n",
    "number of guests/rooms can give me a list of properties and platforms where inventory\n",
    "is available on the given dates.\n",
    "Project Idea: For this web scraping project, first, pick a website serving hotels/property\n",
    "booking facilities, such as MakeMytrip, Agoda, AirBnB or Booking.com. Feed-in your\n",
    "details using an automated fashion, and then you can crawl the website to fetch the\n",
    "ticket price details.\n",
    "You can suitably use tools like Selenium or Pupeteer for performing web scraping in this\n",
    "project.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3f08ac20-bfd2-479a-99db-dee50ab27014",
   "metadata": {},
   "outputs": [],
   "source": [
    "jd5 = \"\"\"\n",
    "Problem Statement for Digital Marketing Professional: Website\n",
    "Visibility & SEO Improvement\n",
    "Overview:\n",
    "I have recently launched a hotel booking website built with ReactJs. It has now been a\n",
    "week since the launch, but unfortunately, the website is not appearing in Google search\n",
    "results or any other major search engines. This is a critical issue as the success of the\n",
    "website heavily relies on organic traffic and visibility. I am looking for a digital marketing\n",
    "professional to conduct an in-depth analysis of the situation, identify the root causes of\n",
    "these issues, and develop a comprehensive digital marketing plan to improve the\n",
    "website's visibility and search engine ranking.\n",
    "Key Objectives:\n",
    "1. Initial Research and Analysis:\n",
    "● Conduct a detailed SEO audit of the website to identify any technical SEO\n",
    "issues.\n",
    "● Analyze if the website has been indexed by Google. If not, identify the reasons.\n",
    "● Review the website to ensure it complies with Google's Webmaster Guidelines.\n",
    "● Verify the presence and accuracy of meta tags, title tags, headers (H1, H2, etc.),\n",
    "and other critical on-page SEO elements.\n",
    "● Check for mobile-friendliness and responsiveness of the website.\n",
    "● Evaluate the website's loading speed and overall performance metrics.\n",
    "● Review content quality and keyword optimization across the pages.\n",
    "2. Competitor Analysis:\n",
    "● Identify key competitors in the hotel booking industry and analyze their digital\n",
    "marketing strategies.\n",
    "● Study competitors' keyword rankings, backlink profiles, and content strategies.\n",
    "● Determine the gaps between my website and competitors' websites in terms of\n",
    "SEO.\n",
    "3. Technical SEO:\n",
    "● Check and fix any issues related to robots.txt file and XML sitemap.\n",
    "● Ensure proper use of canonical tags to avoid duplicate content issues.\n",
    "● Analyze and optimize the website's internal linking structure.\n",
    "● Verify that the website is secure (SSL/TLS).\n",
    "● Audit the website for schema markup implementation and enhancement\n",
    "opportunities.\n",
    "4. Content Strategy:\n",
    "● Evaluate existing content for relevance, uniqueness, and keyword optimization.\n",
    "● Develop a content strategy that includes a mix of blog posts, hotel reviews, travel\n",
    "guides, and other engaging content.\n",
    "● Plan a keyword research strategy to target short-tail and long-tail keywords.\n",
    "● Create a content calendar for consistent publishing.\n",
    "5. User Experience (UX) & Design:\n",
    "● Assess the website’s design for user-friendliness and ease of navigation.\n",
    "● Identify and recommend improvements for user engagement metrics (e.g.,\n",
    "bounce rate, session duration).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7f90a7f8-9a4d-4206-887b-34c911573edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "jd6 = \"\"\"\n",
    "Problem Statement for UX Designers: B2B SaaS Platform for\n",
    "Restaurant Owners and Suppliers\n",
    "Overview:\n",
    "We are developing a pioneering B2B SaaS platform designed to connect restaurant\n",
    "owners with manufacturers and suppliers. This platform aims to streamline the\n",
    "procurement process for restaurant owners while providing manufacturers and suppliers\n",
    "with an efficient avenue to reach their market. Given our diverse user base, which\n",
    "includes individuals with varied levels of digital literacy, the platform must be extremely\n",
    "user-friendly, intuitive, and visually appealing.\n",
    "We need UX designers to create a mobile-first user interface that adapts seamlessly\n",
    "across different devices and screen sizes. The platform should exhibit a consistent\n",
    "styling for color schemes, typography, themes, and layouts, aligning with the Tailwind\n",
    "CSS design system.\n",
    "Key Objectives:\n",
    "1. User Research and Personas:\n",
    "● Conduct comprehensive user research with both restaurant owners and\n",
    "suppliers to understand their needs, pain points, and behavior patterns.\n",
    "● Develop detailed user personas to ensure the design meets the specific needs of\n",
    "these target groups.\n",
    "2. Information Architecture:\n",
    " - Create a logical and intuitive information architecture that facilitates easy navigation\n",
    "through the platform’s features, such as browsing suppliers, placing orders, and tracking\n",
    "shipments.\n",
    " - Design the structure to accommodate future scalability as the platform grows Key\n",
    "Objectives (Continued):\n",
    "3. Wireframes and Prototypes:\n",
    "- Develop wireframes for all major components and user flows, including supplier\n",
    "browsing, order placement, order tracking, user profile management, and\n",
    "communication tools (chat or messaging systems).\n",
    "- Create interactive prototypes to test usability and gather feedback from potential\n",
    "users.\n",
    "- Ensure that the prototypes reflect a mobile-first design approach, while also providing\n",
    "a seamless experience on tablets and desktops.\n",
    "4. Visual Design:\n",
    "- Develop a consistent visual style that aligns with the Tailwind CSS design system,\n",
    "incorporating a coherent color scheme, typography, and themes.\n",
    "- Ensure that the design elements are consistent across all pages and functionalities,\n",
    "creating a unified user experience.\n",
    "- Choose colors, fonts, and layouts that enhance readability and don’t distract users\n",
    "from completing key tasks.\n",
    "5. Responsive Design:\n",
    "- Implement a mobile-first design strategy, ensuring that all features and user interfaces\n",
    "are fully functional and visually appealing on smaller screens.\n",
    "- Design breakpoints and responsive elements to ensure a seamless transition and\n",
    "uniform experience across various devices and screen sizes.\n",
    "6. Accessibility:\n",
    "- Design with accessibility in mind, ensuring that the platform is usable by individuals\n",
    "with disabilities.\n",
    "- Ensure compliance with WCAG (Web Content Accessibility Guidelines) standards to\n",
    "make the platform inclusive for all users.\n",
    "7. User Flows and Interaction Design:\n",
    "- Design intuitive user flows that minimize friction and streamline interactions, ensuring\n",
    "that users can accomplish their goals with minimal steps.\n",
    "- Focus on key interactions, such as searching for suppliers, filtering products, adding\n",
    "items to the cart, and checking out, to ensure a smooth user experience.\n",
    "8. Onboarding and Tutorials:\n",
    "- Develop an effective onboarding process for new users that introduces them to the\n",
    "platform’s features and guides them through initial setup.\n",
    "- Create in-app tutorials and tooltips that assist users in understanding and utilizing the\n",
    "platform’s functionalities.\n",
    "9. Feedback and Iteration:\n",
    "- Implement mechanisms for users to provide feedback on their experience, such as\n",
    "surveys or in-app feedback forms.\n",
    "- Use this feedback to iteratively improve the design, making necessary adjustments to\n",
    "enhance usability and satisfaction.\n",
    "10. Consistency with Tailwind CSS:\n",
    "- Ensure that all design components are built with Tailwind CSS, utilizing its utility-first\n",
    "approach to create a cohesive and maintainable design system.\n",
    "- Leverage Tailwind's predefined style utilities for rapid development and ensure that\n",
    "custom styles are minimal and necessary.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d56f44ff-fbbd-4fe5-a67f-1ece16237225",
   "metadata": {},
   "outputs": [],
   "source": [
    "jd7 = \"\"\"\n",
    "Market Survey\n",
    "Speechofy is a software which is one of the Best AI text to speech for Chromium\n",
    "browsers.\n",
    "Objective: The objective of the project is to speak to potential customers of Speechofy\n",
    "to understand buying behaviour and position Speechofy software.\n",
    "These leads could be followed up by the Speechofy sales team to close the sale. The\n",
    "research on buying behaviour will also enable Speechofy to fine tune its messaging and\n",
    "sales approach to additional leads.\n",
    "Description: Understand Speechofy’s business, products and clients and design a\n",
    "Customer Survey questionnaire. This will be done along with a team at Speechofy.\n",
    "Use the survey questionnaire and speak to 40 potential customers / leads of Speechofy\n",
    "to collect information and position Speechofy as a good solution.\n",
    "Analyse the results of the questionnaire and provide suggestions to Speechofy on how\n",
    "to better message its product to potential customers.\n",
    "A team of 2 students who are pursuing a degree in Marketing or Technology (with\n",
    "knowledge/interest in both technology and marketing) will be the preferred combination\n",
    "for this project.\n",
    "Deliverables: The milestone deliverables for this project should be Design questionnaire\n",
    "(Milestone 1), Conduct customer surveys (Milestone 2), Analyse surveys and provide\n",
    "recommendations to Speechofy for follow up (Milestone 3)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b690b486-06e6-4071-8683-4f63cac6ed7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "jd8 = \"\"\"\n",
    "Problem Statement for Content Writer and Copywriter: Blog on\n",
    "Advances in AI and LLMs\n",
    "Overview:\n",
    "Artificial Intelligence (AI) and Large Language Models (LLMs) have seen unprecedented\n",
    "advancements in recent years, transforming industries and everyday life. As these\n",
    "technologies evolve, they introduce powerful tools that revolutionize how we work,\n",
    "communicate, and solve problems. However, with rapid progress comes a need for\n",
    "comprehensive insights to educate the public about these developments, the major\n",
    "players in the market, the best generative AI software available, and the potential\n",
    "impacts on society, both positive and negative.\n",
    "We are seeking a skilled content writer and copywriter to craft a detailed blog post that\n",
    "explores the recent advancements in AI and LLMs, compares the contributions of\n",
    "leading companies like OpenAI, Google, and Microsoft, and discusses the safety\n",
    "concerns and future threats associated with AI.\n",
    "Key Objectives:\n",
    "1. Introduction to AI and LLMs:\n",
    "- Provide an engaging introduction to AI and Large Language Models, explaining what\n",
    "they are and their significance.\n",
    "- Briefly highlight the historical development of AI and LLMs to give readers context.\n",
    "2. Recent Advancements:\n",
    "- Detail the key advancements in AI and LLMs over the past few years\n",
    "- Discuss significant breakthroughs, such as improvements in natural language\n",
    "processing, machine learning algorithms, and real-world applications.\n",
    "- Include examples of how these advancements are currently being utilized across\n",
    "various industries (e.g., healthcare, finance, customer service).\n",
    "3. Top Generative AI Software:\n",
    "- Highlight and review the best generative AI software on the market, including tools for\n",
    "text generation, image synthesis, and other applications.\n",
    "- Provide a balanced comparison of features, benefits, and limitations of each software.\n",
    "Some prominent examples might include OpenAI's GPT-3 or GPT-4, Google’s BERT\n",
    "and LaMDA, and Microsoft's Azure AI.\n",
    "4. Role of Major Players:\n",
    "- Explore the roles and contributions of key players in the AI landscape:\n",
    "- OpenAI: Discuss its mission, major projects like GPT series, and impact on AI\n",
    "research and accessibility.\n",
    "- Google: Cover initiatives like DeepMind and the use of AI in Google Search, Assistant,\n",
    "and cloud services.\n",
    "- Microsoft: Highlight Microsoft’s integration of AI into Office 365, Azure AI services, and\n",
    "partnerships with organizations like OpenAI.\n",
    "- Analyze how these three giants are shaping the future of AI, their strategic goals, and\n",
    "how they differ in their approach to AI development and deployment.\n",
    "- Discuss any notable collaborations or rivalries between these companies and the\n",
    "implications for the AI ecosystem.\n",
    "5. Safety and Ethical Concerns:\n",
    "- Examine the potential risks and ethical concerns associated with AI and LLMs,\n",
    "including issues of bias, misinformation, privacy, and job displacement.\n",
    "- Discuss the measures being taken by industry leaders and researchers to ensure the\n",
    "safety and ethical use of AI.\n",
    "- Highlight regulatory efforts and guidelines that aim to mitigate risks and promote\n",
    "responsible AI development.\n",
    "6. Future Threats and Opportunities:\n",
    "- Speculate on the potential future threats posed by AI, such as the possibility of AI\n",
    "surpassing human intelligence (superintelligence), cybersecurity risks, and misuse by\n",
    "malicious actors.\n",
    "- Conversely, discuss the transformative potential of AI, including opportunities for\n",
    "solving complex global challenges, advancing scientific research, and improving quality\n",
    "of life.\n",
    "- Include expert opinions and forecasts to provide a balanced view of what the future\n",
    "may hold.\n",
    "7. Conclusion:\n",
    "- Summarize the main points discussed in the blo\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3a606123-1b2f-44c2-aeb4-126fa06bf955",
   "metadata": {},
   "outputs": [],
   "source": [
    "jds = [jd1, jd2, jd3, jd4, jd5, jd6, jd7, jd8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7aa63378-393f-4fd2-96ad-81c738eb9005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Convert the text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation from the text\n",
    "    text = re.sub('[^a-z]', ' ', text)\n",
    "    \n",
    "    # Remove numerical values from the text\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Remove extra whitespaces\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "664a56a8-5271-41cd-8932-f254eb246a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 5 applicants for JD1 are ['Aryan Tayal.pdf', 'Amit Kumar.pdf', 'Akshat Vijay.pdf', 'Anirudh Kohli.pdf', 'Dokala Avinash.pdf']\n",
      "The top 5 applicants for JD2 are ['Anirudh Kohli.pdf', 'Dokala Avinash.pdf', 'Akshat Vijay.pdf', 'Amit Kumar.pdf', 'Abhishek Kumar Tiwari.pdf']\n",
      "The top 5 applicants for JD3 are ['Aryan Tayal.pdf', 'Amit Kumar.pdf', 'Anirudh Kohli.pdf', 'Akshat Vijay.pdf', 'Atul Ranjan.pdf']\n",
      "The top 5 applicants for JD4 are ['Dokala Avinash.pdf', 'Dibyendu Biswas.pdf', 'Anjali Raj.pdf', 'Aryan Tayal.pdf', 'Anirudh Kohli.pdf']\n",
      "The top 5 applicants for JD5 are ['Anirudh Sharma.pdf', 'Aryan Tayal.pdf', 'Aryan Kumar.pdf', 'Amit Kumar.pdf', 'Aditya Krishna Das.pdf']\n",
      "The top 5 applicants for JD6 are ['Aryan Kumar.pdf', 'Doraswamy Vamsi.pdf', 'Atul Ranjan.pdf', 'Amisha Sinha.pdf', 'Aryan Tayal.pdf']\n",
      "The top 5 applicants for JD7 are ['Anirudh Sharma.pdf', 'Aryan Tayal.pdf', 'Amruit Sahoo.pdf', 'Ankesh Kumar.pdf', 'Aryan Kumar.pdf']\n",
      "The top 5 applicants for JD8 are ['Anirudh Kohli.pdf', 'Aryan Tayal.pdf', 'Anirudh Sharma.pdf', 'Aditya Chandrikapure.pdf', 'Aditya Krishna Das.pdf']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "600bc514-f06d-4f4c-a3c7-eff0807c3ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "jd_list = ['Web Development Project', 'Show Me The Money', 'Hiring - Chatbot', 'Web Scraper', 'Problem Statement for Digital Marketing Professional: Website Visibility & SEO Improvement',\n",
    "           'Problem Statement for UX Designers: B2B SaaS Platform for Restaurant Owners and Suppliers', 'Market Survey', \n",
    "           'Problem Statement for Content Writer and Copywriter: Blog on Advances in AI and LLMs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ad060e8e-0236-4542-945c-314bffdcb75d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(jds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f5b27219-a3ea-4f3e-90b9-7c10d821289a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 5 applicants for Web Development Project are ['Aryan Tayal.pdf', 'Amit Kumar.pdf', 'Akshat Vijay.pdf', 'Anirudh Kohli.pdf', 'Dokala Avinash.pdf']\n",
      "The top 5 applicants for Show Me The Money are ['Anirudh Kohli.pdf', 'Dokala Avinash.pdf', 'Akshat Vijay.pdf', 'Amit Kumar.pdf', 'Abhishek Kumar Tiwari.pdf']\n",
      "The top 5 applicants for Hiring - Chatbot are ['Aryan Tayal.pdf', 'Amit Kumar.pdf', 'Anirudh Kohli.pdf', 'Akshat Vijay.pdf', 'Atul Ranjan.pdf']\n",
      "The top 5 applicants for Web Scraper are ['Dokala Avinash.pdf', 'Dibyendu Biswas.pdf', 'Anjali Raj.pdf', 'Aryan Tayal.pdf', 'Anirudh Kohli.pdf']\n",
      "The top 5 applicants for Problem Statement for Digital Marketing Professional: Website Visibility & SEO Improvement are ['Anirudh Sharma.pdf', 'Aryan Tayal.pdf', 'Aryan Kumar.pdf', 'Amit Kumar.pdf', 'Aditya Krishna Das.pdf']\n",
      "The top 5 applicants for Problem Statement for UX Designers: B2B SaaS Platform for Restaurant Owners and Suppliers are ['Aryan Kumar.pdf', 'Doraswamy Vamsi.pdf', 'Atul Ranjan.pdf', 'Amisha Sinha.pdf', 'Aryan Tayal.pdf']\n",
      "The top 5 applicants for Market Survey are ['Anirudh Sharma.pdf', 'Aryan Tayal.pdf', 'Amruit Sahoo.pdf', 'Ankesh Kumar.pdf', 'Aryan Kumar.pdf']\n",
      "The top 5 applicants for Problem Statement for Content Writer and Copywriter: Blog on Advances in AI and LLMs are ['Anirudh Kohli.pdf', 'Aryan Tayal.pdf', 'Anirudh Sharma.pdf', 'Aditya Chandrikapure.pdf', 'Aditya Krishna Das.pdf']\n"
     ]
    }
   ],
   "source": [
    "best = []\n",
    "model = Doc2Vec.load('cv_job_maching1.model')\n",
    "# Apply to CV and JD\n",
    "count = -1\n",
    "for jd in jds:\n",
    "    count += 1\n",
    "    input_JD = preprocess_text(jd)\n",
    "    similarities = []\n",
    "    for resume in resumes:\n",
    "        input_CV = preprocess_text(resume)\n",
    "        v1 = model.infer_vector(input_CV.split())\n",
    "        v2 = model.infer_vector(input_JD.split())\n",
    "        similarity = 100*(np.dot(np.array(v1), np.array(v2))) / (norm(np.array(v1)) * norm(np.array(v2)))\n",
    "        similarities.append(similarity)\n",
    "    res = (sorted(range(len(similarities)), key = lambda sub: similarities[sub])[-5:])\n",
    "    res.reverse()\n",
    "    student_names = []\n",
    "    for index in res:\n",
    "        student_names.append(dir_list[index])\n",
    "    best.append(student_names)\n",
    "    print(f\"The top 5 applicants for {jd_list[count]} are {student_names}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b460dba7-016d-447a-9406-68807fe440c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Aryan Tayal.pdf',\n",
       "  'Amit Kumar.pdf',\n",
       "  'Akshat Vijay.pdf',\n",
       "  'Anirudh Kohli.pdf',\n",
       "  'Dokala Avinash.pdf'],\n",
       " ['Anirudh Kohli.pdf',\n",
       "  'Dokala Avinash.pdf',\n",
       "  'Akshat Vijay.pdf',\n",
       "  'Amit Kumar.pdf',\n",
       "  'Abhishek Kumar Tiwari.pdf'],\n",
       " ['Aryan Tayal.pdf',\n",
       "  'Amit Kumar.pdf',\n",
       "  'Anirudh Kohli.pdf',\n",
       "  'Akshat Vijay.pdf',\n",
       "  'Atul Ranjan.pdf'],\n",
       " ['Dokala Avinash.pdf',\n",
       "  'Dibyendu Biswas.pdf',\n",
       "  'Anjali Raj.pdf',\n",
       "  'Aryan Tayal.pdf',\n",
       "  'Anirudh Kohli.pdf'],\n",
       " ['Anirudh Sharma.pdf',\n",
       "  'Aryan Tayal.pdf',\n",
       "  'Aryan Kumar.pdf',\n",
       "  'Amit Kumar.pdf',\n",
       "  'Aditya Krishna Das.pdf'],\n",
       " ['Aryan Kumar.pdf',\n",
       "  'Doraswamy Vamsi.pdf',\n",
       "  'Atul Ranjan.pdf',\n",
       "  'Amisha Sinha.pdf',\n",
       "  'Aryan Tayal.pdf'],\n",
       " ['Anirudh Sharma.pdf',\n",
       "  'Aryan Tayal.pdf',\n",
       "  'Amruit Sahoo.pdf',\n",
       "  'Ankesh Kumar.pdf',\n",
       "  'Aryan Kumar.pdf'],\n",
       " ['Anirudh Kohli.pdf',\n",
       "  'Aryan Tayal.pdf',\n",
       "  'Anirudh Sharma.pdf',\n",
       "  'Aditya Chandrikapure.pdf',\n",
       "  'Aditya Krishna Das.pdf']]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "13eeb623-9956-4142-8855-046e3c82639a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4eb638d7-347e-4f0e-9ccb-e7aa9fdcf89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Projects' : jd_list,\n",
    "                   'Recommended resumes' : best})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "049ced91-5443-4770-a8af-f675358ccb18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Projects</th>\n",
       "      <th>Recommended resumes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Web Development Project</td>\n",
       "      <td>[Aryan Tayal.pdf, Amit Kumar.pdf, Akshat Vijay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Show Me The Money</td>\n",
       "      <td>[Anirudh Kohli.pdf, Dokala Avinash.pdf, Akshat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hiring - Chatbot</td>\n",
       "      <td>[Aryan Tayal.pdf, Amit Kumar.pdf, Anirudh Kohl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Web Scraper</td>\n",
       "      <td>[Dokala Avinash.pdf, Dibyendu Biswas.pdf, Anja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Problem Statement for Digital Marketing Profes...</td>\n",
       "      <td>[Anirudh Sharma.pdf, Aryan Tayal.pdf, Aryan Ku...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Problem Statement for UX Designers: B2B SaaS P...</td>\n",
       "      <td>[Aryan Kumar.pdf, Doraswamy Vamsi.pdf, Atul Ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Market Survey</td>\n",
       "      <td>[Anirudh Sharma.pdf, Aryan Tayal.pdf, Amruit S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Problem Statement for Content Writer and Copyw...</td>\n",
       "      <td>[Anirudh Kohli.pdf, Aryan Tayal.pdf, Anirudh S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Projects  \\\n",
       "0                            Web Development Project   \n",
       "1                                  Show Me The Money   \n",
       "2                                   Hiring - Chatbot   \n",
       "3                                        Web Scraper   \n",
       "4  Problem Statement for Digital Marketing Profes...   \n",
       "5  Problem Statement for UX Designers: B2B SaaS P...   \n",
       "6                                      Market Survey   \n",
       "7  Problem Statement for Content Writer and Copyw...   \n",
       "\n",
       "                                 Recommended resumes  \n",
       "0  [Aryan Tayal.pdf, Amit Kumar.pdf, Akshat Vijay...  \n",
       "1  [Anirudh Kohli.pdf, Dokala Avinash.pdf, Akshat...  \n",
       "2  [Aryan Tayal.pdf, Amit Kumar.pdf, Anirudh Kohl...  \n",
       "3  [Dokala Avinash.pdf, Dibyendu Biswas.pdf, Anja...  \n",
       "4  [Anirudh Sharma.pdf, Aryan Tayal.pdf, Aryan Ku...  \n",
       "5  [Aryan Kumar.pdf, Doraswamy Vamsi.pdf, Atul Ra...  \n",
       "6  [Anirudh Sharma.pdf, Aryan Tayal.pdf, Amruit S...  \n",
       "7  [Anirudh Kohli.pdf, Aryan Tayal.pdf, Anirudh S...  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8a31e8df-6936-40d5-a8f4-c8ce6309e815",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Recommendations_cos_similarity.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
